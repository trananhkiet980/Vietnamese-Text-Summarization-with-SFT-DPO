{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCKdQktdvPlZ",
        "outputId": "fb6f5fdb-3c7b-46e3-8d1b-f12f999bbfd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.34.6)\n",
            "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: absl-py in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (2.2.2)\n",
            "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (2025.9.18)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py): started\n",
            "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=b1f562813348bde7c002b26308fc76fc392b5eb2ebba5600e87d6f8553ef9996\n",
            "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\1e\\19\\43\\8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score, evaluate\n",
            "\n",
            "   -------------------- ------------------- 1/2 [evaluate]\n",
            "   -------------------- ------------------- 1/2 [evaluate]\n",
            "   -------------------- ------------------- 1/2 [evaluate]\n",
            "   ---------------------------------------- 2/2 [evaluate]\n",
            "\n",
            "Successfully installed evaluate-0.4.6 rouge_score-0.1.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# C√†i ƒë·∫∑t th∆∞ vi·ªán n·∫øu ch∆∞a c√≥\n",
        "!pip install evaluate rouge_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒê√£ l∆∞u 30 d√≤ng ng·∫´u nhi√™n v√†o file test.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "# Load dataset\n",
        "ds = load_dataset(\"OpenHust/vietnamese-summarization\", split=\"train\")  # ho·∫∑c split ph√π h·ª£p n·∫øu bi·∫øt r√µ\n",
        "\n",
        "# L·∫•y ng·∫´u nhi√™n 30 d√≤ng\n",
        "random.seed(42)\n",
        "sample = ds.shuffle(seed=42).select(range(30))\n",
        "\n",
        "# Chuy·ªÉn th√†nh DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"original_text\": sample[\"Document\"],       # t√™n tr∆∞·ªùng c√≥ th·ªÉ kh√°c t√πy dataset\n",
        "    \"reference_summary\": sample[\"Summary\"] # t√™n tr∆∞·ªùng c√≥ th·ªÉ kh√°c\n",
        "})\n",
        "\n",
        "# L∆∞u th√†nh CSV\n",
        "df.to_csv(\"test.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"ƒê√£ l∆∞u 30 d√≤ng ng·∫´u nhi√™n v√†o file test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒêang t·∫£i m√¥ h√¨nh g·ªëc (Qwen/Qwen3-0.6B)...\n",
            "ƒêang t·∫£i m√¥ h√¨nh SFT...\n",
            "ƒêang t·∫£i m√¥ h√¨nh DPO...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1566: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sinh t√≥m t·∫Øt t·ª´ m√¥ h√¨nh g·ªëc...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [13:37<00:00, 27.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sinh t√≥m t·∫Øt t·ª´ m√¥ h√¨nh SFT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [14:01<00:00, 28.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sinh t√≥m t·∫Øt t·ª´ m√¥ h√¨nh DPO...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [11:45<00:00, 23.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== K·∫æT QU·∫¢ ƒê√ÅNH GI√Å ROUGE ===\n",
            "        M√¥ h√¨nh  rouge1  rouge2  rougeL  rougeLsum\n",
            "       Qwen g·ªëc  0.5104  0.1899  0.2981     0.3180\n",
            "Qwen SFT (LoRA)  0.5301  0.2294  0.3184     0.3189\n",
            "  Qwen DPO (RL)  0.5387  0.2304  0.3182     0.3169\n",
            "\n",
            "ƒê√£ l∆∞u k·∫øt qu·∫£ chi ti·∫øt v√†o summarization_results.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import evaluate\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =======================================\n",
        "# üß© 1. ƒê·ªçc d·ªØ li·ªáu test\n",
        "# =======================================\n",
        "df = pd.read_csv(\"test.csv\", encoding=\"utf-8-sig\")\n",
        "texts = df[\"original_text\"].tolist()\n",
        "references = df[\"reference_summary\"].tolist()\n",
        "\n",
        "# =======================================\n",
        "# üß© 2. H√†m sinh t√≥m t·∫Øt\n",
        "# =======================================\n",
        "def generate_summary(model, tokenizer, text, max_new_tokens=100):\n",
        "    prompt = f\"VƒÉn b·∫£n: {text}\\nT√≥m t·∫Øt:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # L·∫•y ph·∫ßn sau \"T√≥m t·∫Øt:\"\n",
        "    if \"T√≥m t·∫Øt:\" in result:\n",
        "        result = result.split(\"T√≥m t·∫Øt:\")[-1].strip()\n",
        "    return result\n",
        "\n",
        "# =======================================\n",
        "# üß© 3. Load c√°c m√¥ h√¨nh\n",
        "# =======================================\n",
        "print(\"ƒêang t·∫£i m√¥ h√¨nh g·ªëc (Qwen/Qwen3-0.6B)...\")\n",
        "model_ori = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\", device_map=\"auto\")\n",
        "tokenizer_ori = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
        "\n",
        "print(\"ƒêang t·∫£i m√¥ h√¨nh SFT...\")\n",
        "model_sft_base = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\", device_map=\"auto\")\n",
        "model_sft = PeftModel.from_pretrained(model_sft_base, \"./runs/qwen3-0.6B-summarization-lora\")\n",
        "tokenizer_sft = AutoTokenizer.from_pretrained(\"./runs/qwen3-0.6B-summarization-lora\")\n",
        "\n",
        "print(\"ƒêang t·∫£i m√¥ h√¨nh DPO...\")\n",
        "model_dpo_base = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\", device_map=\"auto\")\n",
        "model_dpo = PeftModel.from_pretrained(model_dpo_base, \"./runs/dpo-qwen3-0.6B\")\n",
        "tokenizer_dpo = AutoTokenizer.from_pretrained(\"./runs/dpo-qwen3-0.6B\")\n",
        "\n",
        "# =======================================\n",
        "# üß© 4. Sinh t√≥m t·∫Øt cho t·ª´ng m√¥ h√¨nh\n",
        "# =======================================\n",
        "print(\"\\nSinh t√≥m t·∫Øt t·ª´ m√¥ h√¨nh g·ªëc...\")\n",
        "pred_ori = [generate_summary(model_ori, tokenizer_ori, t) for t in tqdm(texts)]\n",
        "\n",
        "print(\"\\nSinh t√≥m t·∫Øt t·ª´ m√¥ h√¨nh SFT...\")\n",
        "pred_sft = [generate_summary(model_sft, tokenizer_sft, t) for t in tqdm(texts)]\n",
        "\n",
        "print(\"\\nSinh t√≥m t·∫Øt t·ª´ m√¥ h√¨nh DPO...\")\n",
        "pred_dpo = [generate_summary(model_dpo, tokenizer_dpo, t) for t in tqdm(texts)]\n",
        "\n",
        "# =======================================\n",
        "# üß© 5. T√≠nh ƒëi·ªÉm ROUGE\n",
        "# =======================================\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def calc_rouge(predictions, references):\n",
        "    scores = rouge.compute(predictions=predictions, references=references)\n",
        "    return {k: round(v, 4) for k, v in scores.items()}\n",
        "\n",
        "scores_ori = calc_rouge(pred_ori, references)\n",
        "scores_sft = calc_rouge(pred_sft, references)\n",
        "scores_dpo = calc_rouge(pred_dpo, references)\n",
        "\n",
        "# =======================================\n",
        "# üß© 6. Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
        "# =======================================\n",
        "df_results = pd.DataFrame([\n",
        "    {\"M√¥ h√¨nh\": \"Qwen g·ªëc\", **scores_ori},\n",
        "    {\"M√¥ h√¨nh\": \"Qwen SFT (LoRA)\", **scores_sft},\n",
        "    {\"M√¥ h√¨nh\": \"Qwen DPO (RL)\", **scores_dpo}\n",
        "])\n",
        "\n",
        "print(\"\\n=== K·∫æT QU·∫¢ ƒê√ÅNH GI√Å ROUGE ===\")\n",
        "print(df_results.to_string(index=False))\n",
        "\n",
        "# =======================================\n",
        "# üß© 7. (T√πy ch·ªçn) L∆∞u t√≥m t·∫Øt ra file CSV\n",
        "# =======================================\n",
        "out_df = pd.DataFrame({\n",
        "    \"original_text\": texts,\n",
        "    \"reference_summary\": references,\n",
        "    \"summary_ori\": pred_ori,\n",
        "    \"summary_sft\": pred_sft,\n",
        "    \"summary_dpo\": pred_dpo\n",
        "})\n",
        "out_df.to_csv(\"summarization_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"\\nƒê√£ l∆∞u k·∫øt qu·∫£ chi ti·∫øt v√†o summarization_results.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
